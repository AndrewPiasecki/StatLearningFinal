data <- read_csv(myurl)
ggplot(data, aes(x = Date, y = Attendance)) +
geom_point() +
ggtitle("Super Bowl Attendance") +
guides(x =  guide_axis(angle = 90)) +
scale_y_continuous(labels = function(x) format(x, scientific = FALSE))
TeamWins <- table(data$'Winner')
TeamWins
TeamWins_df <- as.data.frame(TeamWins)
TeamWins_df
TeamWins_df <- TeamWins_df[order(-TeamWins_df$Freq), ]
TeamWins_df
ggplot(TeamWins_df, aes(x = Var1, y = Freq)) +
geom_bar(stat = "identity") +
guides(x =  guide_axis(angle = 90)) +
labs(title = "Super Bowl Wins by Team",
x = "Team",
y= "Wins")
average_win_points <- mean(data$Winning_Pts)
average_win_points
average_losing_points <- mean(data$Losing_Pts)
average_losing_points
average_win_points - average_losing_points
ggplot() +
geom_point(data = data, aes(x = Date, y = Winning_Pts, color = "Winning_Pts"), size = 3) +
geom_point(data = data, aes(x = Date, y = Losing_Pts, color = "Losing_Pts"), size = 3) +
scale_color_manual(values = c("Winning_Pts" = "darkgreen", "Losing_Pts" = "blue")) +
guides(x = guide_axis(angle = 90)) +
labs(color = "Points Type") +
ggtitle("Winning and Losing Points Over Time") +
xlab("Date") +
ylab("Points")
QB_and_MVP <- data$MVP == data$QB_Winner
ggplot(data, aes(x = QB_and_MVP)) +
geom_bar(stat = "count") +
scale_x_discrete(labels = c("False", "True")) +
labs(title = "MVP and QB are the same player?",
x = "MVP and QB Winner are the Same",
y = "Count")
ggplot(data, aes(x = data$MVP, y = data$QB_Winner)) +
geom_raster(aes(fill = condition), width = 1, height = 1) +
scale_fill_manual(values = c("TRUE" = "green", "FALSE" = "red")) +
labs(title = "True/False Table")
ggplot(data, aes(x = data$MVP, y = data$QB_Winner)) +
geom_bar(aes(fill = condition), width = 1, height = 1) +
scale_fill_manual(values = c("TRUE" = "green", "FALSE" = "red")) +
labs(title = "True/False Table")
ggplot(data, aes(x = QB_and_MVP)) +
geom_bar(stat = "count", color = "red") +
scale_x_discrete(labels = c("False", "True")) +
labs(title = "MVP and QB are the same player?",
x = "MVP and QB Winner are the Same",
y = "Count")
Percentage_QB_MVP <- count(data$MVP == data$QB_Winner)
Percentage_QB_MVP <- (data$MVP == data$QB_Winner)
Percentage_QB_MVP
ggplot(data, aes(x = QB_and_MVP)) +
geom_bar(stat = "count") +
scale_x_discrete(labels = c("False", "True")) +
labs(title = "MVP and QB are the same player?",
x = "MVP and QB Winner are the Same",
y = "Count")
Percentage_QB_MVP <- (25 / 28) * 100
Percentage_QB_MVP
Percentage_QB_MVP <- (data$MVP == data$QB_Winner) == TRUE
Percentage_QB_MVP
Percentage_QB_MVP <- (data$MVP == data$QB_Winner) == 'TRUE'
Percentage_QB_MVP
Percentage_QB_MVP <- (28 / 53) * 100
Percentage_QB_MVP
library(tidyverse)
library(dplyr)
library(ggplot2)
library(scales)
library(tibble)
library(lubridate)
# read data given by Professor Sanchez-Arias
myurl <- "https://raw.githubusercontent.com/reisanar/datasets/master/super_bowl.csv"
data <- read_csv(myurl)
ggplot(data, aes(x = Date, y = Attendance)) +
geom_point() +
ggtitle("Super Bowl Attendance") +
guides(x =  guide_axis(angle = 90)) +
scale_y_continuous(labels = function(x) format(x, scientific = FALSE))
TeamWins <- table(data$'Winner')
TeamWins
TeamWins_df <- as.data.frame(TeamWins)
TeamWins_df
TeamWins_df <- TeamWins_df[order(-TeamWins_df$Freq), ]
TeamWins_df
ggplot(TeamWins_df, aes(x = Var1, y = Freq)) +
geom_bar(stat = "identity") +
guides(x =  guide_axis(angle = 90)) +
labs(title = "Super Bowl Wins by Team",
x = "Team",
y= "Wins")
average_win_points <- mean(data$Winning_Pts)
average_win_points
average_losing_points <- mean(data$Losing_Pts)
average_losing_points
average_win_points - average_losing_points
ggplot() +
geom_point(data = data, aes(x = Date, y = Winning_Pts, color = "Winning_Pts"), size = 3) +
geom_point(data = data, aes(x = Date, y = Losing_Pts, color = "Losing_Pts"), size = 3) +
scale_color_manual(values = c("Winning_Pts" = "darkgreen", "Losing_Pts" = "blue")) +
guides(x = guide_axis(angle = 90)) +
labs(color = "Points Type") +
ggtitle("Winning and Losing Points Over Time") +
xlab("Date") +
ylab("Points")
QB_and_MVP <- data$MVP == data$QB_Winner
ggplot(data, aes(x = QB_and_MVP)) +
geom_bar(stat = "count") +
scale_x_discrete(labels = c("False", "True")) +
labs(title = "MVP and QB are the same player?",
x = "MVP and QB Winner are the Same",
y = "Count")
library(tidyverse)
library(dplyr)
library(ggplot2)
library(scales)
library(tibble)
library(lubridate)
# read data given by Professor Sanchez-Arias
myurl <- "https://raw.githubusercontent.com/reisanar/datasets/master/super_bowl.csv"
data <- read_csv(myurl)
ggplot(data, aes(x = Date, y = Attendance)) +
geom_point() +
ggtitle("Super Bowl Attendance") +
guides(x =  guide_axis(angle = 90)) +
scale_y_continuous(labels = function(x) format(x, scientific = FALSE))
TeamWins <- table(data$'Winner')
TeamWins
TeamWins_df <- as.data.frame(TeamWins)
TeamWins_df
TeamWins_df <- TeamWins_df[order(-TeamWins_df$Freq), ]
TeamWins_df
ggplot(TeamWins_df, aes(x = Var1, y = Freq)) +
geom_bar(stat = "identity") +
guides(x =  guide_axis(angle = 90)) +
labs(title = "Super Bowl Wins by Team",
x = "Team",
y= "Wins")
average_win_points <- mean(data$Winning_Pts)
average_win_points
average_losing_points <- mean(data$Losing_Pts)
average_losing_points
average_win_points - average_losing_points
ggplot() +
geom_point(data = data, aes(x = Date, y = Winning_Pts, color = "Winning_Pts"), size = 3) +
geom_point(data = data, aes(x = Date, y = Losing_Pts, color = "Losing_Pts"), size = 3) +
scale_color_manual(values = c("Winning_Pts" = "darkgreen", "Losing_Pts" = "blue")) +
guides(x = guide_axis(angle = 90)) +
labs(color = "Points Type") +
ggtitle("Winning and Losing Points Over Time") +
xlab("Date") +
ylab("Points")
QB_and_MVP <- data$MVP == data$QB_Winner
ggplot(data, aes(x = QB_and_MVP)) +
geom_bar(stat = "count") +
scale_x_discrete(labels = c("False", "True")) +
labs(title = "MVP and QB are the same player?",
x = "MVP and QB Winner are the Same",
y = "Count")
Percentage_QB_MVP <- (28 / 53) * 100
Percentage_QB_MVP
# Load the FactoMineR package
library(FactoMineR)
# Load the FactoMineR package
install.packages("FactoMineR")
library(FactoMineR)
# Load your data into a data frame or matrix
data <- read.csv("data.csv")  # Replace with your own data file or data frame
# Load your data into a data frame or matrix
data <- read.csv("https://raw.githubusercontent.com/reisanar/datasets/master/super_bowl.csv")  # Replace with your own data file or data frame
# Perform PCA
result <- PCA(data, scale.unit = TRUE, graph = FALSE)
View(data)
# Perform PCA
result <- PCA(data$Attendance, scale.unit = TRUE, graph = FALSE)
result
# Extract PCA results
eigenvalues <- result$eig
eigenvectors <- result$var$coord
scores <- result$ind$coord
# Access the eigenvalues
print("Eigenvalues:")
print(eigenvalues)
# Access the eigenvectors (principal components)
print("Eigenvectors (Principal Components):")
print(eigenvectors)
# Access the scores (coordinates of individuals in the principal components space)
print("Scores (Individuals' Coordinates in PCA Space):")
print(scores)
plot(scores)
# Load data from a CSV file hosted on GitHub
url <- "https://raw.githubusercontent.com/reisanar/datasets/master/super_bowl.csv"
data <- read.csv(url)
# Perform PCA on the 'Attendance' variable
result <- PCA(data$Attendance, scale.unit = TRUE, graph = FALSE)
# Extract PCA results
eigenvalues <- result$eig
eigenvectors <- result$var$coord
scores <- result$ind$coord
# Print the eigenvalues
cat("Eigenvalues:\n")
print(eigenvalues)
# Print the eigenvectors (principal components)
cat("\nEigenvectors (Principal Components):\n")
print(eigenvectors)
# Print the scores (coordinates of individuals in the principal components space)
cat("\nScores (Individuals' Coordinates in PCA Space):\n")
print(scores)
# Plot the PCA scores
plot(scores, main = "PCA Scores", xlab = "PC1", ylab = "PC2")
library(dplyr)
library(dplyr)
library(ggplot2)
library(dplyr)
library(ggplot2)
library(scales)
library(tibble)
library(FactoMineR)
library(ggplot2)
# Load data from the CSV file
url <- "https://raw.githubusercontent.com/reisanar/datasets/master/super_bowl.csv"
data <- read.csv(url)
# Extract PCA results
eigenvectors <- result$var$coord
scores <- result$ind$coord
# Print the eigenvectors (principal components)
cat("Eigenvectors (Principal Components):\n")
print(eigenvectors)
# Print the scores (coordinates of individuals in the principal components space)
cat("\nScores (Individuals' Coordinates in PCA Space):\n")
print(scores)
# Plot the PCA scores on the first two principal components
ggplot(data.frame(scores), aes(x = Dim.1, y = Dim.2)) +
geom_point(size = 3) +
labs(title = "PCA Scores", x = "PC1", y = "PC2") +
theme_minimal()
# Load required libraries
library(tidyverse)
library(caret)
# Load required libraries
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("caret")
library(tidyverse)
library(caret)
library(tidyverse)
library(caret)
# Load the dataset
url <- "https://raw.githubusercontent.com/reisanar/datasets/master/super_bowl.csv"
super_bowl <- read.csv(url)
# Remove unnecessary columns
super_bowl <- select(super_bowl, -c(Date, SB, QB_Winner, Coach_Winner, QB_Loser, Coach_Loser, MVP, Stadium, City, State, Referee, Umpire, Head_Linesman, Line_Judge, Field_Judge, Back_Judge, Side_Judge))
# Load required libraries
install.packages("caret")
library(tidyverse)
# Load required libraries
install.packages(caret)
library(caret)
# Load required libraries
install.packages("caret)
# Load required libraries
install.packages("caret")
# Load required libraries
install.packages("caret")
library(tidyverse)
install.packages(c("blob", "broom", "car", "cli", "commonmark", "dbplyr", "dplyr", "dtplyr", "ggplot2", "ggsci", "googledrive", "googlesheets4", "gtable", "hms", "htmltools", "lme4", "markdown", "modelr", "pillar", "ps", "quantreg", "rlang", "rmarkdown", "testthat", "xfun"))
install.packages(c("blob", "broom", "car", "cli", "commonmark", "dbplyr", "dplyr", "dtplyr", "ggplot2", "ggsci", "googledrive", "googlesheets4", "gtable", "hms", "htmltools", "lme4", "markdown", "modelr", "pillar", "ps", "quantreg", "rlang", "rmarkdown", "testthat", "xfun"))
install.packages(c("blob", "broom", "car", "cli", "commonmark", "dbplyr", "dplyr", "dtplyr", "ggplot2", "ggsci", "googledrive", "googlesheets4", "gtable", "hms", "htmltools", "lme4", "markdown", "modelr", "pillar", "ps", "quantreg", "rlang", "rmarkdown", "testthat", "xfun"))
install.packages(c("blob", "broom", "car", "cli", "commonmark", "dbplyr", "dplyr", "dtplyr", "ggplot2", "ggsci", "googledrive", "googlesheets4", "gtable", "hms", "htmltools", "lme4", "markdown", "modelr", "pillar", "ps", "quantreg", "rlang", "rmarkdown", "testthat", "xfun"))
install.packages(c("blob", "broom", "car", "cli", "commonmark", "dbplyr", "dplyr", "dtplyr", "ggplot2", "ggsci", "googledrive", "googlesheets4", "gtable", "hms", "htmltools", "lme4", "markdown", "modelr", "pillar", "ps", "quantreg", "rlang", "rmarkdown", "testthat", "xfun"))
install.packages(c("blob", "broom", "car", "cli", "commonmark", "dbplyr", "dplyr", "dtplyr", "ggplot2", "ggsci", "googledrive", "googlesheets4", "gtable", "hms", "htmltools", "lme4", "markdown", "modelr", "pillar", "ps", "quantreg", "rlang", "rmarkdown", "testthat", "xfun"))
install.packages(c("blob", "broom", "car", "cli", "commonmark", "dbplyr", "dplyr", "dtplyr", "ggplot2", "ggsci", "googledrive", "googlesheets4", "gtable", "hms", "htmltools", "lme4", "markdown", "modelr", "pillar", "ps", "quantreg", "rlang", "rmarkdown", "testthat", "xfun"))
install.packages(c("blob", "broom", "car", "cli", "commonmark", "dbplyr", "dplyr", "dtplyr", "ggplot2", "ggsci", "googledrive", "googlesheets4", "gtable", "hms", "htmltools", "lme4", "markdown", "modelr", "pillar", "ps", "quantreg", "rlang", "rmarkdown", "testthat", "xfun"))
library(caret)
library(tidyverse)
install.packages(c("cli", "htmltools", "rlang", "xfun"))
install.packages(c("cli", "htmltools", "rlang", "xfun"))
install.packages(c("cli", "htmltools", "rlang", "xfun"))
install.packages(c("cli", "htmltools", "rlang", "xfun"))
install.packages(c("cli", "htmltools", "rlang", "xfun"))
install.packages("rlang")
install.packages("rlang")
library(tidyverse)
install.packages(c("cli", "htmltools", "rlang", "xfun"))
install.packages(c("boot", "class", "codetools", "foreign", "lattice", "MASS", "Matrix", "mgcv", "nlme", "spatial", "survival"), lib="C:/Program Files/R/R-4.2.2/library")
# Load required libraries
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("caret")
library(tidyverse)
library(caret)
library(tidyverse)
library(caret)
# Load the dataset
url <- "https://raw.githubusercontent.com/reisanar/datasets/master/super_bowl.csv"
super_bowl <- read.csv(url)
super_bowl <- read.csv(url)
# Remove unnecessary columns
super_bowl <- select(super_bowl, -c(Date, SB, QB_Winner, Coach_Winner, QB_Loser, Coach_Loser, MVP, Stadium, City, State, Referee, Umpire, Head_Linesman, Line_Judge, Field_Judge, Back_Judge, Side_Judge))
# Convert columns with factors to character
super_bowl <- mutate_if(super_bowl, is.factor, as.character)
# Convert columns with dates to Date format
super_bowl$Date <- as.Date(super_bowl$Date, format = "%d-%b-%y")
# Convert columns with numeric values to numeric
num_cols <- c("Attendance", "Winning_Pts", "Losing_Pts", "Point_Difference")
super_bowl[num_cols] <- lapply(super_bowl[num_cols], as.numeric)
# Data preprocessing
# Remove rows with missing values
super_bowl <- na.omit(super_bowl)
# Standardize numeric columns
num_cols <- c("Attendance", "Winning_Pts", "Losing_Pts", "Point_Difference")
super_bowl_scaled <- scale(super_bowl[num_cols])
# Perform PCA
pca <- prcomp(super_bowl_scaled, center = TRUE, scale. = TRUE)
# Extract PCA results
pca_scores <- pca$x
pca_loadings <- pca$rotation
# Cross-validation
# Set seed for reproducibility
set.seed(123)
# Create training and test sets
train_indices <- createDataPartition(y = super_bowl$Winner, p = 0.8, list = FALSE)
train_data <- super_bowl[train_indices, ]
test_data <- super_bowl[-train_indices, ]
# Perform PCA on training data
train_data_scaled <- scale(train_data[num_cols])
pca_train <- prcomp(train_data_scaled, center = TRUE, scale. = TRUE)
# Extract PCA results on training data
train_pca_scores <- pca_train$x
train_pca_loadings <- pca_train$rotation
# Apply PCA on test data using PCA results from training data
test_data_scaled <- scale(test_data[num_cols], center = attr(train_data_scaled, "scaled:center"), scale = attr(train_data_scaled, "scaled:scale"))
test_pca_scores <- predict(pca_train, test_data_scaled)$x
# Model training and evaluation
# Create a logistic regression model with PCA scores as predictors
model <- train(Winner ~ ., data = data.frame(train_pca_scores, Winner = train_data$Winner), method = "glm", family = "binomial")
# Make predictions on test data
predictions <- predict(model, data.frame(test_pca_scores, Winner = test_data$Winner))
# Calculate accuracy of the model
accuracy <- sum(predictions == test_data$Winner) / nrow(test_data)
# Print results
cat("Accuracy of the model: ", round(accuracy * 100, 2), "%\n")
cat("Proportion of variance explained by each principal component:\n")
print(pca$sdev^2 / sum(pca$sdev^2))
View(pca)
# Read the dataset
data <- read.csv("https://raw.githubusercontent.com/reisanar/datasets/master/super_bowl.csv") # Replace "your_dataset.csv" with the actual file name or URL
# Perform PCA
# Select relevant columns for PCA
pca_data <- data %>%
select(SB, Attendance, Winning_Pts, Losing_Pts, Point_Difference)
# Scale the data
scaled_data <- scale(pca_data)
# Perform PCA
pca_result <- prcomp(scaled_data)
# Extract the scores and loadings
scores <- as.data.frame(pca_result$x)
loadings <- as.data.frame(pca_result$rotation)
data$SB <- as.numeric(data$SB)
data$Attendance <- as.numeric(data$Attendance)
data$Winning_Pts <- as.numeric(data$Winning_Pts)
data$Losing_Pts <- as.numeric(data$Losing_Pts)
data$Point_Difference <- as.numeric(data$Point_Difference)
# Perform PCA
# Select relevant columns for PCA
pca_data <- data %>%
select(SB, Attendance, Winning_Pts, Losing_Pts, Point_Difference)
# Scale the data
scaled_data <- scale(pca_data)
# Perform PCA
pca_result <- prcomp(scaled_data)
# Check for columns with no variability
constant_cols <- colnames(pca_data)[apply(pca_data, 2, function(x) length(unique(x)) <= 1)]
# Remove constant columns
if (length(constant_cols) > 0) {
pca_data <- pca_data %>%
select(-one_of(constant_cols))
}
# Perform PCA
pca_result <- prcomp(scaled_data)
# Extract the scores and loadings
scores <- as.data.frame(pca_result$x)
loadings <- as.data.frame(pca_result$rotation)
View(pca_data)
View(scaled_data)
# Perform PCA
pca_result <- prcomp(scaled_data)
View(scaled_data)
plot(scaled_data)
plot(scaled_data, xlim = 2)
ggplot(scaled_data)
ggplot(scaled_data) +
geom_point()
ggplot(data, aes(x = scaled_data) +
ggplot(data, aes(x = scaled_data)) +
geom_point()
ggplot(data, aes(x = scaled_data)) +
# Check for columns with no variability
constant_cols <- colnames(data)[apply(data, 2, function(x) length(unique(x)) <= 1)]
# Remove constant columns
if (length(constant_cols) > 0) {
data <- data %>%
select(-one_of(constant_cols))
}
# Check data types
if (!all(sapply(data, is.numeric))) {
stop("Dataset contains non-numeric columns. Please convert all relevant columns to numeric before proceeding.")
}
# Scale the data
scaled_data <- scale(pca_data)
# Perform PCA
pca_result <- prcomp(scaled_data)
# Extract the scores and loadings
scores <- as.data.frame(pca_result$x)
loadings <- as.data.frame(pca_result$rotation)
# Perform cross-validation
# Prepare data for modeling
data_for_modeling <- data %>%
select(SB, Attendance, Winning_Pts, Losing_Pts, Point_Difference) # Select relevant columns for modeling
pca_result
# Convert scaled data to data frame
scaled_data_df <- as.data.frame(scaled_data)
# Create scatter plot of PC1 and PC2
ggplot(scaled_data_df, aes(x = PC1, y = PC2)) +
geom_point() +
xlab("PC1") +
ylab("PC2") +
ggtitle("Scatter plot of PC1 and PC2")
# Perform PCA on the scaled data
pca <- prcomp(scaled_data, center = TRUE, scale. = TRUE)
# Extract the principal components from the PCA result
pc_scores <- pca$x
# Convert PC scores to a data frame
pc_scores_df <- as.data.frame(pc_scores)
# Create scatter plot of PC1 and PC2
ggplot(pc_scores_df, aes(x = PC1, y = PC2)) +
geom_point() +
xlab("PC1") +
ylab("PC2") +
ggtitle("Scatter plot of PC1 and PC2")
# Create scatter plot of PC1 and PC2
ggplot(scaled_data_df, aes(x = PC1, y = PC2)) +
geom_point() +
geom_line() +
xlab("PC1") +
ylab("PC2") +
ggtitle("Scatter plot of PC1 and PC2")
# Create scatter plot of PC1 and PC2
ggplot(scaled_data_df, aes(x = PC1, y = PC2)) +
geom_point() +
xlab("PC1") +
ylab("PC2") +
ggtitle("Scatter plot of PC1 and PC2")
# Create scatter plot of PC1 and PC2
ggplot(pc_scores_df, aes(x = PC1, y = PC2)) +
geom_point() +
geom_line() +
xlab("PC1") +
ylab("PC2") +
ggtitle("Scatter plot of PC1 and PC2")
# Create scatter plot of PC1 and PC2
ggplot(pc_scores_df, aes(x = PC1, y = PC2)) +
geom_point(method = "lm") +
geom_line() +
xlab("PC1") +
ylab("PC2") +
ggtitle("Scatter plot of PC1 and PC2")
# Create scatter plot of PC1 and PC2
ggplot(pc_scores_df, aes(x = PC1, y = PC2)) +
geom_point() +
geom_line(method = "lm") +
xlab("PC1") +
ylab("PC2") +
ggtitle("Scatter plot of PC1 and PC2")
# Create scatter plot of PC1 and PC2
ggplot(pc_scores_df, aes(x = PC1, y = PC2)) +
geom_point() +
geom_smooth(method = "lm") +
xlab("PC1") +
ylab("PC2") +
ggtitle("Scatter plot of PC1 and PC2")
# Load required libraries
install.packages("rlang")
install.packages("rlang")
# Load required libraries
install.packages("rlang")
install.packages("rlang")
install.packages(c("blob", "broom", "cachem", "car", "caret", "cli", "colorspace", "commonmark", "curl", "data.table", "dbplyr", "dplyr", "dtplyr", "e1071", "evaluate", "fansi", "fastmap", "forcats", "fs", "future", "gargle", "ggplot2", "googledrive", "googlesheets4", "gtable", "hardhat", "haven", "hms", "htmltools", "httr", "ipred", "knitr", "lava", "lme4", "lubridate", "markdown", "modelr", "openssl", "parallelly", "pillar", "prodlim", "ps", "purrr", "quantreg", "readr", "readxl", "recipes", "rlang", "rmarkdown", "sass", "stringi", "tibble", "tidyr", "tidyverse", "timechange", "tinytex", "utf8", "vctrs", "vroom", "xfun", "yaml"))
# Load required libraries
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("caret")
library(tidyverse)
clear
writeLines('PATH="${RTOOLS40_HOME}\\USR\\bin;{PATH}"', con = "~/.Renviron")
Sys.which("make")
install.packages("rlang")
install.packages("readxl")
library(readxl)
library(rlang)
R --version
version
clear
install.packages("tidyselect",INSTALL_opts="--no-multiarch")
